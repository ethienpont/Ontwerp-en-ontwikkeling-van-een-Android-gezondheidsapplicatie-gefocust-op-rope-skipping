{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import matplotlib\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import warnings\n",
    "from scipy.signal import savgol_filter, find_peaks, correlate\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.fftpack as FFT\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.rcParams['figure.figsize'] = [12,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def convert_to_datetime(x):\n",
    "    dt = datetime.fromtimestamp(x // 1000000000)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(x % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def heatmap(cm, labels):\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def preprocess(data, activity, drop_interval_begin = 3, drop_interval_end = 3):\n",
    "    #convert nanoseconds to date \n",
    "    data['time'] = data['time'].apply(convert_to_datetime) \n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "#convert to same data type\n",
    "    for i in range(1, 4): \n",
    "        data[column_names_org[i]] = data[column_names_org[i]].apply(convert_to_float)\n",
    "    \n",
    "#drop rows with NaN values \n",
    "    data.dropna(axis=0, how='any', inplace=True) #TODO: invullen met mean, mod of median / interpolatie\n",
    "\n",
    "#drop duplicates \n",
    "    data.drop_duplicates(subset=None, keep='first', inplace = True)\n",
    "    \n",
    "    #drop first and last 3 sec\n",
    "    indexFirst = data[ (data['time'].iloc[0]+ pd.to_timedelta(drop_interval_begin, unit='s')) > data['time'] ].index\n",
    "    data.drop(indexFirst , inplace=True)\n",
    "    indexLast = data[ (data['time'].iloc[-1]- pd.to_timedelta(drop_interval_end, unit='s')) < data['time'] ].index\n",
    "    data.drop(indexLast , inplace=True)\n",
    "    \n",
    "    #add activity label\n",
    "    data['activity'] = activity\n",
    "    \n",
    "    return data\n",
    "\n",
    "#feature extraction\n",
    "def get_mean_window(df):\n",
    "    return df.mean()\n",
    "\n",
    "def get_min_window(df):\n",
    "    return df.min()\n",
    "\n",
    "def get_max_window(df):\n",
    "    return df.max()\n",
    "\n",
    "def get_std_window(df):\n",
    "    return df.std()\n",
    "\n",
    "def get_med_window(df):\n",
    "    return df.median()\n",
    "\n",
    "#TODO: scipy integrate\n",
    "#TODO: voor elke as apart??\n",
    "#measure of activity level (m/s²)\n",
    "def get_signal_magnitude_area(df):\n",
    "        sum = 0\n",
    "        for i in range(0, len(df)):\n",
    "            sum += (abs(df['x'].iloc[i]) + abs(df['y'].iloc[i]) + abs(df['z'].iloc[i]))\n",
    "        return sum /len(df)\n",
    "    #result = integrate.quad(lambda t: df['x'].apply(lambda n : abs(n)) + df['y'].apply(lambda n : abs(n)) + df['z'].apply(lambda n : abs(n)), 0, len(df))\n",
    "\n",
    "#TODO: voor elke as apart??\n",
    "#degree of movement intensity (m/s²)\n",
    "def get_signal_magnitude_vector(df):\n",
    "    sum = 0\n",
    "    for i in range(0, len(df)):\n",
    "        sum += math.sqrt(df['x'].iloc[i] * df['x'].iloc[i] + df['y'].iloc[i] * df['y'].iloc[i] + df['z'].iloc[i] * df['z'].iloc[i])\n",
    "    return sum\n",
    "\n",
    "#average angle (radian) between accelerometer vector and x as (parallel with arm)\n",
    "def get_tilt_angle(df):\n",
    "    df_cos = pd.DataFrame(columns=[\"tilt_ang\"])\n",
    "    df_dot = df['x']\n",
    "    for i in range(0, len(df)):\n",
    "        s = pd.Series({\"tilt_ang\" : (df_dot.iloc[i])/(math.sqrt(df['x'].iloc[i]*df['x'].iloc[i] + df['y'].iloc[i]*df['y'].iloc[i] + df['z'].iloc[i]*df['z'].iloc[i]))})\n",
    "        df_cos=df_cos.append(s, ignore_index=True)\n",
    "    df_angle = np.arccos(df_cos)\n",
    "    return df_angle.mean()['tilt_ang']\n",
    "\n",
    "def get_power_spectral_density(df):\n",
    "    df_psd = np.abs(df)**2\n",
    "    return df_psd.sum()\n",
    "\n",
    "#TODO: datatype is object en niet compex nr\n",
    "def get_entropy(df):\n",
    "    entropy = []\n",
    "    pdf = df / df.sum()\n",
    "    for i in range (1, len(pdf.columns)):\n",
    "        entropy.append(np.complex(-np.nansum(pdf.iloc[:,i] * np.log2(pdf.iloc[:,i]))))\n",
    "    return entropy\n",
    "\n",
    "#generate windows with 50% overlap\n",
    "def windows(df, time, overlap):\n",
    "    start = df.iloc[0]\n",
    "    while  (start + pd.to_timedelta(time, unit='s')) < df.iloc[-1]:\n",
    "        yield start, (start + pd.to_timedelta(time, unit='s'))\n",
    "        if overlap:\n",
    "            start += pd.to_timedelta(time/2, unit='s')\n",
    "        else:\n",
    "            start += pd.to_timedelta(time, unit='s')\n",
    "    #last samples \n",
    "    yield (df.iloc[-1] - pd.to_timedelta(time, unit='s')), df.iloc[-1]\n",
    "        \n",
    "def feature_extraction_segmentation(data, window, overlap):\n",
    "    column_names = [\"x_mean\", \"y_mean\", \"z_mean\", \"x_min\", \"y_min\", \"z_min\", \"x_max\", \"y_max\", \"z_max\",\n",
    "                \"x_std\", \"y_std\", \"z_std\", \"x_med\", \"y_med\", \"z_med\", \"activity\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    for (start, end) in windows(data['time'], window, overlap):\n",
    "        vw1 = data['time'] >= start\n",
    "        vw2 = data['time'] < end\n",
    "        mean = get_mean_window(data[vw1 & vw2])\n",
    "        min = get_min_window(data[vw1 & vw2])\n",
    "        max = get_max_window(data[vw1 & vw2])\n",
    "        std = get_std_window(data[vw1 & vw2])\n",
    "        med = get_med_window(data[vw1 & vw2])\n",
    "        sma = get_signal_magnitude_area(data[vw1 & vw2])\n",
    "        smv = get_signal_magnitude_vector(data[vw1 & vw2])\n",
    "        tilt = get_tilt_angle(data[vw1 & vw2])\n",
    "        #fourrier transform\n",
    "        t_x = data[vw1 & vw2][['time','x']].set_index('time')\n",
    "        t_y = data[vw1 & vw2][['time','y']].set_index('time')\n",
    "        t_z = data[vw1 & vw2][['time', 'z']].set_index('time')\n",
    "\n",
    "        df_f = pd.DataFrame(columns=['f', 'x_f', 'y_f', 'z_f'])\n",
    "\n",
    "    #TODO: determine sampling rate (datapoints per second)\n",
    "        sampling_rate = 52\n",
    "\n",
    "        df_f['x_f'] = FFT.fft(t_x).ravel()\n",
    "        df_f['y_f'] = FFT.fft(t_y).ravel()\n",
    "        df_f['z_f'] = FFT.fft(t_z).ravel()\n",
    "        df_f['f'] = FFT.fftfreq(len(df_f['x_f'])) * sampling_rate\n",
    "\n",
    "        psd = get_power_spectral_density(df_f)\n",
    "        #entropy = get_entropy(df_f)\n",
    "\n",
    "        df = df.append(pd.Series({'x_mean': mean['x'], 'y_mean': mean['y'], 'z_mean': mean['z'], \"x_min\" : min['x'],\n",
    "                              \"y_min\" : min['y'], \"z_min\" : min['z'], \"x_max\" : max['x'], \"y_max\" : max['y'], \"z_max\" : max['z'],\n",
    "                              \"x_std\" : std['x'], \"y_std\" : std['y'], \"z_std\" : std['z'], \"x_med\" : med['x'], \"y_med\" : med['y'], \"z_med\" : med['z'],\n",
    "                              \"sma\" : sma, \"smv\" : smv, \"tilt\" : tilt, \"x_psd\" : psd['x_f'], \"y_psd\" : psd['y_f'], \"z_psd\" : psd['z_f']\n",
    "                              , \"activity\" : data['activity'].iloc[0]}), ignore_index=True) # \"x_entropy\" : entropy[0], \"y_entropy\" : entropy[1], \"z_entropy\" : entropy[2],\n",
    "    return df\n",
    "\n",
    "#3 keer savgol filter uitvoeren met 33,5\n",
    "def get_turns_smooth_side_swing(df):\n",
    "    for i in range(0,5):\n",
    "        df['x'] = savgol_filter(df[ 'x'].to_numpy(), 101, 5)\n",
    "        df['y'] = savgol_filter(df[ 'y'].to_numpy(), 101, 5)\n",
    "        df['z'] = savgol_filter(df[ 'z'].to_numpy(), 101, 5)\n",
    "        df.plot(x='time', subplots=True)\n",
    "\n",
    "    wx = find_peaks(df['x'])\n",
    "    wy = find_peaks(df['y'])\n",
    "    wz = find_peaks(df['z'])\n",
    "    return (len(wx[0]) + len(wy[0]) + len(wz[0]))/3\n",
    "\n",
    "\n",
    "column_names_org = ['time', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' >PROEFPERSOON 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_left_forward-tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_tim(meting2).csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_left_backwards_tim1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake4 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_left_backwards_tim2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake5 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_left_backwards_tim3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake6 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_right_backwards_tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake7 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_right_backwards_tim2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake8 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon1\\jump_fast_right_backwards_tim3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "mistake9 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake10 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_left_forward_tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "mistake11 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_right_backwards_tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake12 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_right_backwards_tim1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake13 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_left_backwards_tim1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake14 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_left_backwards_tim2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake15 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_left_backwards_tim3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake16 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_tim.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "mistake17 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon1\\jump_slow_left_forward_tim.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake1 = preprocess(mistake1, \"mistake\", 1,1)\n",
    "mistake3 = preprocess(mistake3, \"mistake\", 1,1)\n",
    "mistake6 = preprocess(mistake6, \"mistake\", 1,1)\n",
    "mistake13 = preprocess(mistake13, \"mistake\", 1,1)\n",
    "mistake14 = preprocess(mistake14, \"mistake\", 1,1)\n",
    "mistake15 = preprocess(mistake15, \"mistake\", 1,1)\n",
    "mistake16 = preprocess(mistake16, \"mistake\", 1,1)\n",
    "mistake17 = preprocess(mistake17, \"mistake\", 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>1970-01-02 01:02:04.909584384</td>\n",
       "      <td>-3.617948</td>\n",
       "      <td>-3.876373</td>\n",
       "      <td>2.019542</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>1970-01-02 01:02:04.934750208</td>\n",
       "      <td>-2.622534</td>\n",
       "      <td>-1.512264</td>\n",
       "      <td>1.557728</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>1970-01-02 01:02:04.951527424</td>\n",
       "      <td>-2.378466</td>\n",
       "      <td>-2.450250</td>\n",
       "      <td>-1.610370</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1970-01-02 01:02:04.968304640</td>\n",
       "      <td>-1.899901</td>\n",
       "      <td>-5.852844</td>\n",
       "      <td>-2.471786</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>1970-01-02 01:02:04.993470464</td>\n",
       "      <td>-0.775275</td>\n",
       "      <td>-4.007978</td>\n",
       "      <td>-3.251846</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>1970-01-02 01:02:06.318870528</td>\n",
       "      <td>-3.625126</td>\n",
       "      <td>1.093520</td>\n",
       "      <td>9.391829</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>1970-01-02 01:02:06.318870528</td>\n",
       "      <td>-3.639483</td>\n",
       "      <td>1.184447</td>\n",
       "      <td>9.485149</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>1970-01-02 01:02:06.335647744</td>\n",
       "      <td>-3.639483</td>\n",
       "      <td>1.184447</td>\n",
       "      <td>9.485149</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>1970-01-02 01:02:06.360813568</td>\n",
       "      <td>-3.639483</td>\n",
       "      <td>1.184447</td>\n",
       "      <td>9.485149</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>1970-01-02 01:02:06.394368000</td>\n",
       "      <td>-3.548556</td>\n",
       "      <td>0.969093</td>\n",
       "      <td>9.346365</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time         x         y         z activity\n",
       "372 1970-01-02 01:02:04.909584384 -3.617948 -3.876373  2.019542  mistake\n",
       "373 1970-01-02 01:02:04.934750208 -2.622534 -1.512264  1.557728  mistake\n",
       "374 1970-01-02 01:02:04.951527424 -2.378466 -2.450250 -1.610370  mistake\n",
       "375 1970-01-02 01:02:04.968304640 -1.899901 -5.852844 -2.471786  mistake\n",
       "376 1970-01-02 01:02:04.993470464 -0.775275 -4.007978 -3.251846  mistake\n",
       "..                            ...       ...       ...       ...      ...\n",
       "442 1970-01-02 01:02:06.318870528 -3.625126  1.093520  9.391829  mistake\n",
       "443 1970-01-02 01:02:06.318870528 -3.639483  1.184447  9.485149  mistake\n",
       "444 1970-01-02 01:02:06.335647744 -3.639483  1.184447  9.485149  mistake\n",
       "445 1970-01-02 01:02:06.360813568 -3.639483  1.184447  9.485149  mistake\n",
       "446 1970-01-02 01:02:06.394368000 -3.548556  0.969093  9.346365  mistake\n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut1 = mistake1[mistake1[\"time\"] >= pd.to_datetime(\"1970-01-01 01:08:57.0000\")]\n",
    "cut2 = mistake3[mistake3[\"time\"] >= pd.to_datetime(\"1970-01-02 01:02:04.9000\")]\n",
    "cut3 = mistake6[mistake6[\"time\"] >= pd.to_datetime(\"1970-01-01 21:18:04.9100\")]\n",
    "cut4 = mistake13[mistake13[\"time\"] >= pd.to_datetime(\"1970-01-02 00:59:40.0000\")]\n",
    "cut5 = mistake14[mistake14[\"time\"] >= pd.to_datetime(\"1970-01-02 01:00:45.7000\")]\n",
    "cut6 = mistake15[mistake15[\"time\"] >= pd.to_datetime(\"1970-01-02 01:01:30.6000\")]\n",
    "cut7 = mistake16[mistake16[\"time\"] >= pd.to_datetime(\"1970-01-01 11:40:06.9000\")]\n",
    "cut2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "niet gewoon achter elkaar plakken, want is niet realistisch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1 = feature_extraction_segmentation(cut1,1, True)\n",
    "cut2 = feature_extraction_segmentation(cut2,1, True)\n",
    "cut3 = feature_extraction_segmentation(cut3,1, True)\n",
    "cut4 = feature_extraction_segmentation(cut4,1, True)\n",
    "cut5 = feature_extraction_segmentation(cut5,1, True)\n",
    "cut6 = feature_extraction_segmentation(cut6,1, True)\n",
    "cut7 = feature_extraction_segmentation(cut7,1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 22)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes_1 = pd.concat([cut1, cut2, cut3, cut4, cut5, cut6, cut7],  ignore_index=True)\n",
    "mistakes_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' >PROEFPERSOON 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "cross_over_right_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over_right_backwards1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_right_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over_right_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_right_backwards3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over_right_backwards3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_right_forward1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_right_forward1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_right_forward2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_right_forward2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_right_forward3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_right_forward3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_left_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossover_backwards.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_left_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossover_backwards(2).csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_left_backwards3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_left_backwards.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_left_backwards4 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_left_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over_left_backwards5 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\crossOver_left_backwards3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over3.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over4 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over4.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "cross_over5 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\cross_over\\proefpersoon2\\cross_over5.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "jump_slow_right_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow_right_backwards1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_right_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow_right_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_turn_diff = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow_turn_diff.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_rigth = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow_right1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_rigth2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow_right2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_rigth3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jumpslow_right_forward.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow_rigth4 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jumpslow_right_forward2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_slow2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_slow\\proefpersoon2\\jump_slow1 (meting2).csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "jump_fast_right_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast_right_backwards1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast_right_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast_right_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast_left_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast_backwards.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast_right_forward1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast_right_forward1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast_right_forward2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast_right_forward2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "jump_fast2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\jump_fast\\proefpersoon2\\jump_fast (meting2).csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1970-01-01 04:38:00.990842880</td>\n",
       "      <td>-1.842473</td>\n",
       "      <td>-9.738789</td>\n",
       "      <td>-6.283552</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1970-01-01 04:38:00.998182912</td>\n",
       "      <td>-1.864009</td>\n",
       "      <td>-9.934999</td>\n",
       "      <td>-6.257231</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1970-01-01 04:38:01.004474368</td>\n",
       "      <td>-1.933401</td>\n",
       "      <td>-10.083355</td>\n",
       "      <td>-5.644669</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1970-01-01 04:38:01.027543040</td>\n",
       "      <td>-1.962115</td>\n",
       "      <td>-10.408778</td>\n",
       "      <td>-5.668597</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1970-01-01 04:38:01.041174528</td>\n",
       "      <td>-1.962115</td>\n",
       "      <td>-10.408778</td>\n",
       "      <td>-5.668597</td>\n",
       "      <td>mistake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time         x          y         z activity\n",
       "63 1970-01-01 04:38:00.990842880 -1.842473  -9.738789 -6.283552  mistake\n",
       "64 1970-01-01 04:38:00.998182912 -1.864009  -9.934999 -6.257231  mistake\n",
       "65 1970-01-01 04:38:01.004474368 -1.933401 -10.083355 -5.644669  mistake\n",
       "66 1970-01-01 04:38:01.027543040 -1.962115 -10.408778 -5.668597  mistake\n",
       "67 1970-01-01 04:38:01.041174528 -1.962115 -10.408778 -5.668597  mistake"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistake1 = preprocess(cross_over_right_backwards1, \"mistake\",1,1)\n",
    "mistake2 = preprocess(cross_over_right_backwards2, \"mistake\",1,1)\n",
    "mistake3 = preprocess(cross_over_right_backwards3, \"mistake\",1,1)\n",
    "mistake4 = preprocess(cross_over_right_forward1, \"mistake\",1,1)\n",
    "mistake5 = preprocess(cross_over_right_forward2, \"mistake\",1,1)\n",
    "mistake6 = preprocess(cross_over_left_backwards1, \"mistake\",1,1)\n",
    "mistake7 = preprocess(cross_over_left_backwards2, \"mistake\",1,1)\n",
    "mistake8 = preprocess(cross_over_left_backwards3, \"mistake\",1,1)\n",
    "mistake9 = preprocess(cross_over_left_backwards5, \"mistake\",1,1)\n",
    "mistake10 = preprocess(cross_over2, \"mistake\",1,1)\n",
    "mistake11 = preprocess(jump_slow_right_backwards1, \"mistake\",1,1)\n",
    "mistake12 = preprocess(jump_slow_turn_diff, \"mistake\",1,1)\n",
    "mistake13 = preprocess(jump_fast_right_backwards1, \"mistake\",1,1)\n",
    "mistake14 = preprocess(jump_fast_right_backwards2, \"mistake\",1,1)\n",
    "mistake15 = preprocess(jump_fast_left_backwards1, \"mistake\",1,1)\n",
    "mistake16 = preprocess(jump_fast_right_forward1, \"mistake\",1,1)\n",
    "mistake17 = preprocess(jump_fast_right_forward2, \"mistake\",1,1)\n",
    "mistake18 = preprocess(jump_fast, \"mistake\",1,1)\n",
    "mistake19 = preprocess(jump_fast2, \"mistake\",1,1)\n",
    "mistake19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1 = mistake1[mistake1['time'] >= pd.to_datetime(\"1970-01-02 01:08:20.7000\")]\n",
    "cut2 = mistake2[mistake2['time'] >= pd.to_datetime(\"1970-01-02 01:09:22.4000\")]\n",
    "cut3 = mistake3[mistake3['time'] >= pd.to_datetime(\"1970-01-02 01:10:10.8000\")]\n",
    "cut4 = mistake4[mistake4['time'] >= pd.to_datetime(\"1970-01-01 21:24:27.6000\")]\n",
    "cut5 = mistake5[mistake5['time'] >= pd.to_datetime(\"1970-01-01 21:24:54.3500\")]\n",
    "cut6 = mistake6[mistake6['time'] >= pd.to_datetime(\"1970-01-01 01:48:41.9500\")]\n",
    "cut7 = mistake7[mistake7['time'] >= pd.to_datetime(\"1970-01-01 01:49:13.0500\")]\n",
    "cut8 = mistake8[mistake8['time'] >= pd.to_datetime(\"1970-01-01 18:24:46.4500\")] #kan mss in 2 gesplitst worden want piek ertussen, slechtere detectie??\n",
    "cut9 = mistake9[mistake9['time'] >= pd.to_datetime(\"1970-01-01 18:26:20.2000\")]\n",
    "cut10 = mistake10[mistake10['time'] >= pd.to_datetime(\"1970-01-01 11:20:13.3500\")]\n",
    "cut11 = mistake11[mistake11['time'] >= pd.to_datetime(\"1970-01-02 01:12:21.5000\")]\n",
    "cut12 = mistake12[mistake12['time'] >= pd.to_datetime(\"1970-01-01 11:27:34.6000\")]\n",
    "cut13 = mistake13[mistake13['time'] >= pd.to_datetime(\"1970-01-02 01:06:08.1000\")]\n",
    "cut14 = mistake14[mistake14['time'] >= pd.to_datetime(\"1970-01-02 01:07:07.7000\")]\n",
    "cut15 = mistake15[mistake15['time'] >= pd.to_datetime(\"1970-01-01 01:46:25.9000\")]\n",
    "cut16 = mistake16[mistake16['time'] >= pd.to_datetime(\"1970-01-01 21:22:13.3000\")]\n",
    "cut17 = mistake17[mistake17['time'] >= pd.to_datetime(\"1970-01-01 21:23:18.2000\")]   #piek\n",
    "cut18 = mistake18[mistake18['time'] >= pd.to_datetime(\"1970-01-01 01:24:11.1200\")]\n",
    "cut19 = mistake19[mistake19['time'] >= pd.to_datetime(\"1970-01-01 04:38:42.5000\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1 = feature_extraction_segmentation(cut1,1, True)\n",
    "cut2 = feature_extraction_segmentation(cut2,1, True)\n",
    "cut3 = feature_extraction_segmentation(cut3,1, True)\n",
    "cut4 = feature_extraction_segmentation(cut4,1, True)\n",
    "cut5 = feature_extraction_segmentation(cut5,1, True)\n",
    "cut6 = feature_extraction_segmentation(cut6,1, True)\n",
    "cut7 = feature_extraction_segmentation(cut7,1, True)\n",
    "cut8= feature_extraction_segmentation(cut8,1, True)\n",
    "cut9= feature_extraction_segmentation(cut9,1, True)\n",
    "cut10 = feature_extraction_segmentation(cut10,1, True)\n",
    "cut11 = feature_extraction_segmentation(cut11,1, True)\n",
    "cut12 = feature_extraction_segmentation(cut12,1, True)\n",
    "cut13 = feature_extraction_segmentation(cut13, 1,True)\n",
    "cut14 = feature_extraction_segmentation(cut14,1, True)\n",
    "cut15 = feature_extraction_segmentation(cut15,1, True)\n",
    "cut16 = feature_extraction_segmentation(cut16, 1,True)\n",
    "cut17 = feature_extraction_segmentation(cut17,1, True)\n",
    "cut18 = feature_extraction_segmentation(cut18, 1,True)\n",
    "cut19 = feature_extraction_segmentation(cut19,1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 22)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes = pd.concat([cut1, cut2, cut3, cut4, cut5, cut6, cut7, cut8,cut9, cut10,cut11, cut12, cut13, cut14, cut15, cut16, cut17, cut18, cut19  ],  ignore_index=True)\n",
    "mistakes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
