{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import matplotlib\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import warnings\n",
    "from scipy.signal import savgol_filter, find_peaks, correlate\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.fftpack as FFT\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.rcParams['figure.figsize'] = [12,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_freq(df):\n",
    "    start = df['time'].iloc[0]\n",
    "    sum_samples = 0\n",
    "    index = 0\n",
    "    while  (start + pd.to_timedelta(1, unit='s')) < df['time'].iloc[-1]:\n",
    "        end =  start + pd.to_timedelta(1, unit='s')\n",
    "        sum_samples += df[(df['time'] >= start) & (df['time'] < end)].shape[0]\n",
    "        start += pd.to_timedelta(1, unit='s')\n",
    "        index += 1\n",
    "    return sum_samples/index\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def convert_to_datetime(x):\n",
    "    dt = datetime.fromtimestamp(x // 1000000000)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(x % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def heatmap(cm, labels):\n",
    "    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def preprocess(data, activity, type_, p, drop_interval_begin = 3, drop_interval_end = 3):\n",
    "    #convert nanoseconds to date \n",
    "    data['time'] = data['time'].apply(convert_to_datetime) \n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "#convert to same data type\n",
    "    for i in range(1, 4): \n",
    "        data[column_names_org[i]] = data[column_names_org[i]].apply(convert_to_float)\n",
    "    \n",
    "#drop rows with NaN values \n",
    "    data.dropna(axis=0, how='any', inplace=True) #TODO: invullen met mean, mod of median / interpolatie\n",
    "\n",
    "#drop duplicates \n",
    "    data.drop_duplicates(subset=None, keep='first', inplace = True)\n",
    "    \n",
    "    #drop first and last 3 sec\n",
    "    indexFirst = data[ (data['time'].iloc[0]+ pd.to_timedelta(drop_interval_begin, unit='s')) > data['time'] ].index\n",
    "    data.drop(indexFirst , inplace=True)\n",
    "    indexLast = data[ (data['time'].iloc[-1]- pd.to_timedelta(drop_interval_end, unit='s')) < data['time'] ].index\n",
    "    data.drop(indexLast , inplace=True)\n",
    "    \n",
    "    #add activity label\n",
    "    data['activity'] = activity\n",
    "    data['type'] = type_\n",
    "    data['proefpersoon'] = p\n",
    "    \n",
    "    return data\n",
    "\n",
    "#feature extraction\n",
    "def get_mean_window(df):\n",
    "    return df.mean()\n",
    "\n",
    "def get_min_window(df):\n",
    "    return df.min()\n",
    "\n",
    "def get_max_window(df):\n",
    "    return df.max()\n",
    "\n",
    "def get_std_window(df):\n",
    "    return df.std()\n",
    "\n",
    "def get_med_window(df):\n",
    "    return df.median()\n",
    "\n",
    "#TODO: scipy integrate\n",
    "#TODO: voor elke as apart??\n",
    "#measure of activity level (m/s²)\n",
    "def get_signal_magnitude_area(df):\n",
    "        sum = 0\n",
    "        for i in range(0, len(df)):\n",
    "            sum += (abs(df['x'].iloc[i]) + abs(df['y'].iloc[i]) + abs(df['z'].iloc[i]))\n",
    "        return sum /len(df)\n",
    "    #result = integrate.quad(lambda t: df['x'].apply(lambda n : abs(n)) + df['y'].apply(lambda n : abs(n)) + df['z'].apply(lambda n : abs(n)), 0, len(df))\n",
    "\n",
    "#TODO: voor elke as apart??\n",
    "#degree of movement intensity (m/s²)\n",
    "def get_signal_magnitude_vector(df):\n",
    "    sum = 0\n",
    "    for i in range(0, len(df)):\n",
    "        sum += math.sqrt(df['x'].iloc[i] * df['x'].iloc[i] + df['y'].iloc[i] * df['y'].iloc[i] + df['z'].iloc[i] * df['z'].iloc[i])\n",
    "    return sum\n",
    "\n",
    "#average angle (radian) between accelerometer vector and x as (parallel with arm)\n",
    "def get_tilt_angle(df):\n",
    "    df_cos = pd.DataFrame(columns=[\"tilt_ang\"])\n",
    "    df_dot = df['x']\n",
    "    for i in range(0, len(df)):\n",
    "        s = pd.Series({\"tilt_ang\" : (df_dot.iloc[i])/(math.sqrt(df['x'].iloc[i]*df['x'].iloc[i] + df['y'].iloc[i]*df['y'].iloc[i] + df['z'].iloc[i]*df['z'].iloc[i]))})\n",
    "        df_cos=df_cos.append(s, ignore_index=True)\n",
    "    df_angle = np.arccos(df_cos)\n",
    "    return df_angle.mean()['tilt_ang']\n",
    "\n",
    "def get_power_spectral_density(df):\n",
    "    df_psd = np.abs(df)**2\n",
    "    return df_psd.sum()\n",
    "\n",
    "#TODO: datatype is object en niet compex nr\n",
    "def get_entropy(df):\n",
    "    entropy = []\n",
    "    pdf = df / df.sum()\n",
    "    for i in range (1, len(pdf.columns)):\n",
    "        entropy.append(np.complex(-np.nansum(pdf.iloc[:,i] * np.log2(pdf.iloc[:,i]))))\n",
    "    return entropy\n",
    "\n",
    "#generate windows with 50% overlap\n",
    "def windows(df, time, overlap):\n",
    "    start = df.iloc[0]\n",
    "    while  (start + pd.to_timedelta(time, unit='s')) < df.iloc[-1]:\n",
    "        yield start, (start + pd.to_timedelta(time, unit='s'))\n",
    "        if overlap:\n",
    "            start += pd.to_timedelta(time/2, unit='s')\n",
    "        else:\n",
    "            start += pd.to_timedelta(time, unit='s')\n",
    "    #last samples \n",
    "    yield (df.iloc[-1] - pd.to_timedelta(time, unit='s')), df.iloc[-1]\n",
    "        \n",
    "def feature_extraction_segmentation(data, window, overlap):\n",
    "    column_names = [\"x_mean\", \"y_mean\", \"z_mean\", \"x_min\", \"y_min\", \"z_min\", \"x_max\", \"y_max\", \"z_max\",\n",
    "                \"x_std\", \"y_std\", \"z_std\", \"x_med\", \"y_med\", \"z_med\", \"activity\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    for (start, end) in windows(data['time'], window, overlap):\n",
    "        vw1 = data['time'] >= start\n",
    "        vw2 = data['time'] < end\n",
    "        mean = get_mean_window(data[vw1 & vw2])\n",
    "        min = get_min_window(data[vw1 & vw2])\n",
    "        max = get_max_window(data[vw1 & vw2])\n",
    "        std = get_std_window(data[vw1 & vw2])\n",
    "        med = get_med_window(data[vw1 & vw2])\n",
    "        sma = get_signal_magnitude_area(data[vw1 & vw2])\n",
    "        smv = get_signal_magnitude_vector(data[vw1 & vw2])\n",
    "        tilt = get_tilt_angle(data[vw1 & vw2])\n",
    "        #fourrier transform\n",
    "        t_x = data[vw1 & vw2][['time','x']].set_index('time')\n",
    "        t_y = data[vw1 & vw2][['time','y']].set_index('time')\n",
    "        t_z = data[vw1 & vw2][['time', 'z']].set_index('time')\n",
    "\n",
    "        df_f = pd.DataFrame(columns=['f', 'x_f', 'y_f', 'z_f'])\n",
    "\n",
    "    #TODO: determine sampling rate (datapoints per second)\n",
    "        sampling_rate = 52\n",
    "\n",
    "        df_f['x_f'] = FFT.fft(t_x).ravel()\n",
    "        df_f['y_f'] = FFT.fft(t_y).ravel()\n",
    "        df_f['z_f'] = FFT.fft(t_z).ravel()\n",
    "        df_f['f'] = FFT.fftfreq(len(df_f['x_f'])) * sampling_rate\n",
    "\n",
    "        psd = get_power_spectral_density(df_f)\n",
    "        #entropy = get_entropy(df_f)\n",
    "\n",
    "        df = df.append(pd.Series({'x_mean': mean['x'], 'y_mean': mean['y'], 'z_mean': mean['z'], \"x_min\" : min['x'],\n",
    "                              \"y_min\" : min['y'], \"z_min\" : min['z'], \"x_max\" : max['x'], \"y_max\" : max['y'], \"z_max\" : max['z'],\n",
    "                              \"x_std\" : std['x'], \"y_std\" : std['y'], \"z_std\" : std['z'], \"x_med\" : med['x'], \"y_med\" : med['y'], \"z_med\" : med['z'],\n",
    "                              \"sma\" : sma, \"smv\" : smv, \"tilt\" : tilt, \"x_psd\" : psd['x_f'], \"y_psd\" : psd['y_f'], \"z_psd\" : psd['z_f']\n",
    "                              , \"activity\" : data['activity'].iloc[0]}), ignore_index=True) # \"x_entropy\" : entropy[0], \"y_entropy\" : entropy[1], \"z_entropy\" : entropy[2],\n",
    "    return df\n",
    "\n",
    "#3 keer savgol filter uitvoeren met 33,5\n",
    "def get_turns_smooth_side_swing(df):\n",
    "    for i in range(0,5):\n",
    "        df['x'] = savgol_filter(df[ 'x'].to_numpy(), 101, 5)\n",
    "        df['y'] = savgol_filter(df[ 'y'].to_numpy(), 101, 5)\n",
    "        df['z'] = savgol_filter(df[ 'z'].to_numpy(), 101, 5)\n",
    "        df.plot(x='time', subplots=True)\n",
    "\n",
    "    wx = find_peaks(df['x'])\n",
    "    wy = find_peaks(df['y'])\n",
    "    wz = find_peaks(df['z'])\n",
    "    return (len(wx[0]) + len(wy[0]) + len(wz[0]))/3\n",
    "\n",
    "\n",
    "column_names_org = ['time', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = True\n",
    "freq = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' >PROEFPERSOON 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backward 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_1 = []\n",
    "backward_180_right_right_1= []\n",
    "backward_180_left_left_1 = []\n",
    "backward_180_right_left_1= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_left_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_left_backwards_tim1.csv' does not exist: b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_left_backwards_tim1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d4f57a011849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#8 SEGMENTEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforward_180_left_backwards1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_left_backwards_tim1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_left_backwards_tim1.csv' does not exist: b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_left_backwards_tim1.csv'"
     ]
    }
   ],
   "source": [
    "#8 SEGMENTEN\n",
    "forward_180_left_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_left_backwards_tim1.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_left_backwards1[forward_180_left_backwards1[\"time\"] <= 31979000000000]\n",
    "f2 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31979000000000) & (forward_180_left_backwards1[\"time\"] <= 31983000000000)]\n",
    "f3 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31983000000000) & (forward_180_left_backwards1[\"time\"] <= 31987500000000)]\n",
    "f4 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31987500000000) & (forward_180_left_backwards1[\"time\"] <= 31991800000000)]\n",
    "f5 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31991800000000) & (forward_180_left_backwards1[\"time\"] <= 31995800000000)]\n",
    "f6 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31995800000000) & (forward_180_left_backwards1[\"time\"] <= 31999900000000)]\n",
    "f7 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 31999900000000) & (forward_180_left_backwards1[\"time\"] <= 32004400000000)]\n",
    "f8 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 32004400000000) & (forward_180_left_backwards1[\"time\"] <= 32009000000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 1.2, 0.8)\n",
    "f2 = preprocess(f2, \"backward_180\", 0.9, 0.5)\n",
    "f3 = preprocess(f3, \"backward_180\", 1, 1)\n",
    "f4 = preprocess(f4, \"backward_180\", 0.8, 0.9)\n",
    "f5 = preprocess(f5, \"backward_180\", 0.8, 0.9)\n",
    "f6 = preprocess(f6, \"backward_180\", 0.8, 0.8)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.1, 0.9)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_left_backwards_1 = [f1,f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180a = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_left_right_tim1.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180a = preprocess(backward_180a, \"backward_180\", \"left_right\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_1 = [backward_180a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_left_right_1:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_right_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_right_backwards_tim1.csv' does not exist: b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_right_backwards_tim1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-309f8187546f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#EERSTE EN LAATSTE STUKJES NIET GEKNIPT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#5 SEGMENTEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mforward_180_right_backwards1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#3 SEGMENTEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_right_backwards_tim1.csv' does not exist: b'C:\\\\Users\\\\Elise\\\\Documents\\\\unif\\\\master\\\\semester2\\\\masterproef\\\\gitProject\\\\thesis\\\\data\\\\forward_180\\\\proefpersoon1\\\\forward_180_right_backwards_tim1.csv'"
     ]
    }
   ],
   "source": [
    "#EERSTE EN LAATSTE STUKJES NIET GEKNIPT\n",
    "#5 SEGMENTEN\n",
    "forward_180_right_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "#3 SEGMENTEN\n",
    "forward_180_right_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "forward_180_right_backwards4 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim4.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "forward_180_right_backwards5 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim5.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "forward_180_right_backwards6 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_tim6.csv\", sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 =  forward_180_right_backwards1[(forward_180_right_backwards1[\"time\"] >= 11918100000000) & (forward_180_right_backwards1[\"time\"] <= 11923700000000)]\n",
    "f3 =  forward_180_right_backwards1[(forward_180_right_backwards1[\"time\"] >= 11923700000000) & (forward_180_right_backwards1[\"time\"] <= 11929200000000)]\n",
    "f4 =  forward_180_right_backwards1[(forward_180_right_backwards1[\"time\"] >= 11929200000000) & (forward_180_right_backwards1[\"time\"] <= 11935500000000)]\n",
    "f5 =  forward_180_right_backwards1[(forward_180_right_backwards1[\"time\"] >= 11935500000000) & (forward_180_right_backwards1[\"time\"] <= 11941400000000)]\n",
    "\n",
    "f6 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] <= 11951900000000)]\n",
    "f7 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] >= 11951900000000) & (forward_180_right_backwards2[\"time\"] <= 11956800000000)]\n",
    "f8 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] >= 11956800000000) & (forward_180_right_backwards2[\"time\"] <= 11961900000000)]\n",
    "\n",
    "f9 =  forward_180_right_backwards4[(forward_180_right_backwards4[\"time\"] >= 11976300000000)]\n",
    "f10 = forward_180_right_backwards4[(forward_180_right_backwards4[\"time\"] <= 11976300000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = preprocess(f2, \"backward_180\", 1.7, 0.9)\n",
    "f3 = preprocess(f3, \"backward_180\", 1, 1.2)\n",
    "f4 = preprocess(f4, \"backward_180\", 1.5, 1.7)\n",
    "f5 = preprocess(f5, \"backward_180\", 2, 1)\n",
    "f6 = preprocess(f6, \"backward_180\", 1, 1)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.5, 1.5)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.7, 1.5)\n",
    "f9 = preprocess(f9, \"backward_180\", 1.5, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_right_backwards_1 = [f2, f3, f4, f5, f6, f7, f8, f9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_righta = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_right_right_tim.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "backward_180_right_rightb = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_right_right_tim2.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_righta = preprocess(backward_180_right_righta, \"backward_180\", \"right_right\", 1)\n",
    "backward_180_right_rightb = preprocess(backward_180_right_rightb, \"backward_180\", \"right_right\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_right_1 = [backward_180_right_righta, backward_180_right_rightb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_right_right_1:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_left_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 segmenten\n",
    "forward_180_left_backwards_other1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_left_backwards_tim_other_side1.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_left_backwards_other1[forward_180_left_backwards_other1[\"time\"] <= 32379000000000]\n",
    "f2 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32379000000000) & (forward_180_left_backwards_other1[\"time\"] <= 32383100000000)]\n",
    "f3 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32383100000000) & (forward_180_left_backwards_other1[\"time\"] <= 32387300000000)]\n",
    "f4 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32387300000000) & (forward_180_left_backwards_other1[\"time\"] <= 32391400000000)]\n",
    "f5 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32391400000000) & (forward_180_left_backwards_other1[\"time\"] <= 32395500000000)]\n",
    "f6 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32395500000000) & (forward_180_left_backwards_other1[\"time\"] <= 32399600000000)]\n",
    "f7 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32399600000000) & (forward_180_left_backwards_other1[\"time\"] <= 32403800000000)]\n",
    "f8 =  forward_180_left_backwards_other1[(forward_180_left_backwards_other1[\"time\"] >= 32403800000000) & (forward_180_left_backwards_other1[\"time\"] <= 32408100000000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 0.8, 0.6)\n",
    "f2 = preprocess(f2, \"backward_180\", 1, 0.7)\n",
    "f3 = preprocess(f3, \"backward_180\", 1.3, 0.6)\n",
    "f4 = preprocess(f4, \"backward_180\", 1.2, 0.6)\n",
    "f5 = preprocess(f5, \"backward_180\", 1.1, 0.7)\n",
    "f6 = preprocess(f6, \"backward_180\", 1.3, 0.6)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.2, 0.7)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.2, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_left_backwards_other_side_1 = [f1,f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_lefta = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_left_left_tim1.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_lefta = preprocess(backward_180_left_lefta, \"backward_180\", \"left_left\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_left_1 = [backward_180_left_lefta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_left_left_1:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_right_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 SEGMENTEN\n",
    "forward_180_right_backwards_other1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_other_side_tim1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "#1 SEGMENT\n",
    "forward_180_right_backwards_other2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\forward_180_right_backwards_other_side_tim2.csv\", sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_right_backwards_other1[forward_180_right_backwards_other1[\"time\"] <= 31867200000000]\n",
    "f2 =  forward_180_right_backwards_other1[(forward_180_right_backwards_other1[\"time\"] >= 31867200000000) & (forward_180_right_backwards_other1[\"time\"] <= 31871500000000)]\n",
    "f3 =  forward_180_right_backwards_other1[(forward_180_right_backwards_other1[\"time\"] >= 31871500000000) & (forward_180_right_backwards_other1[\"time\"] <= 31875700000000)]\n",
    "f4 =  forward_180_right_backwards_other1[(forward_180_right_backwards_other1[\"time\"] >= 31875700000000) & (forward_180_right_backwards_other1[\"time\"] <= 31880400000000)]\n",
    "f5 =  forward_180_right_backwards_other1[(forward_180_right_backwards_other1[\"time\"] >= 31880400000000) & (forward_180_right_backwards_other1[\"time\"] <= 31885400000000)]\n",
    "f6 =  forward_180_right_backwards_other1[(forward_180_right_backwards_other1[\"time\"] >= 31885400000000) & (forward_180_right_backwards_other1[\"time\"] <= 31889600000000)]\n",
    "f7 =  forward_180_right_backwards_other1[forward_180_right_backwards_other1[\"time\"] >= 31889600000000]\n",
    "\n",
    "f8 =  forward_180_right_backwards_other2[forward_180_right_backwards_other2[\"time\"] <= 31918500000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 1.8, 0.4)\n",
    "f2 = preprocess(f2, \"backward_180\", 1.2, 0.4)\n",
    "f3 = preprocess(f3, \"backward_180\", 1.2, 0.6)\n",
    "f4 = preprocess(f4, \"backward_180\", 1.2, 0.6)\n",
    "f5 = preprocess(f5, \"backward_180\", 2, 0.6)\n",
    "f6 = preprocess(f6, \"backward_180\", 1.2, 0.6)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.2, 4.8)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_right_backwards_other_side_1 = [f1,f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_lefta = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_right_left_tim1.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "backward_180_right_leftb = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon1\\backward_180_right_left_tim2.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_lefta = preprocess(backward_180_right_lefta, \"backward_180\", \"right_left\",1, 3, 4)\n",
    "backward_180_right_leftb = preprocess(backward_180_right_leftb, \"backward_180\", \"right_left\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_left_1 = [backward_180_right_lefta, backward_180_right_leftb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_right_left_1:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( not raw):\n",
    "    #segmentation + feature extraction\n",
    "    for i in range(0, len(backward_180_left_right_1)):\n",
    "        backward_180_left_right_1[i] =  feature_extraction_segmentation(backward_180_left_right_1[i],1, True)\n",
    "\n",
    "    for i in range(0, len(backward_180_right_right_1)):\n",
    "        backward_180_right_right_1[i] =  feature_extraction_segmentation(backward_180_right_right_1[i],1, True)\n",
    "\n",
    "    for i in range(0, len(backward_180_left_left_1)):\n",
    "        backward_180_left_left_1[i] =  feature_extraction_segmentation(backward_180_left_left_1[i],1, True)\n",
    "    \n",
    "    for i in range(0, len(backward_180_right_left_1)):\n",
    "        backward_180_right_left_1[i] =  feature_extraction_segmentation(backward_180_right_left_1[i],1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2706, 7)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_left_right_1 = pd.concat(backward_180_left_right_1, ignore_index=True)\n",
    "backward_180_left_right_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3226, 7)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_right_right_1 = pd.concat(backward_180_right_right_1, ignore_index=True)\n",
    "backward_180_right_right_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3017, 7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_left_left_1 = pd.concat(backward_180_left_left_1, ignore_index=True)\n",
    "backward_180_left_left_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3865, 7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_right_left_1 = pd.concat(backward_180_right_left_1, ignore_index=True)\n",
    "backward_180_right_left_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHUFFLE - BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2706"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = np.min([\n",
    "    backward_180_left_right_1.shape[0], \n",
    "    backward_180_right_right_1.shape[0], \n",
    "    backward_180_left_left_1.shape[0], \n",
    "    backward_180_right_left_1.shape[0]])\n",
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_1 = shuffle(backward_180_left_right_1).head(shape).copy()\n",
    "backward_180_right_right_1 = shuffle(backward_180_right_right_1).head(shape).copy()\n",
    "backward_180_left_left_1 = shuffle(backward_180_left_left_1).head(shape).copy()\n",
    "backward_180_right_left_1 = shuffle(backward_180_right_left_1).head(shape).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_1 = backward_180_left_right_1.head(shape).copy()\n",
    "backward_180_right_right_1 = backward_180_right_right_1.head(shape).copy()\n",
    "backward_180_left_left_1 = backward_180_left_left_1.head(shape).copy()\n",
    "backward_180_right_left_1 = backward_180_right_left_1.head(shape).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_1 = pd.concat([backward_180_left_right_1, backward_180_right_right_1, backward_180_left_left_1, backward_180_right_left_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' >PROEFPERSOON 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backward 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2 = []\n",
    "backward_180_right_right_2= []\n",
    "backward_180_left_left_2 = []\n",
    "backward_180_right_left_2= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_left_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 SEGMENTEN\n",
    "forward_180_left_backwards1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_left_backwards1.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "\n",
    "#1 SEGMENT\n",
    "forward_180_left_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_left_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "forward_180_left_backwards3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_left_backwards3.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] <= 11248600000000)]\n",
    "f2 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11248600000000) & (forward_180_left_backwards1[\"time\"] <= 11253300000000)]\n",
    "f3 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11253300000000) & (forward_180_left_backwards1[\"time\"] <= 11258300000000)]\n",
    "f4 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11258300000000) & (forward_180_left_backwards1[\"time\"] <= 11263400000000)]\n",
    "f5 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11263400000000) & (forward_180_left_backwards1[\"time\"] <= 11268300000000)]\n",
    "f6 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11268300000000) & (forward_180_left_backwards1[\"time\"] <= 11273000000000)]\n",
    "f7 =  forward_180_left_backwards1[(forward_180_left_backwards1[\"time\"] >= 11273000000000)]\n",
    "\n",
    "f8 =  forward_180_left_backwards2[(forward_180_left_backwards2[\"time\"] <= 11287300000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 1, 0.7)\n",
    "f2 = preprocess(f2, \"backward_180\", 1, 1)\n",
    "f3 = preprocess(f3, \"backward_180\", 1.3, 0.9)\n",
    "f4 = preprocess(f4, \"backward_180\", 1.4, 0.9)\n",
    "f5 = preprocess(f5, \"backward_180\", 1.2, 1)\n",
    "f6 = preprocess(f6, \"backward_180\", 1.1, 1)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.2, 2.4)\n",
    "f8 = preprocess(f8, \"backward_180\", 2, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_left_backwards_2 = [f1, f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2a = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\backward_180_left_right.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2a = preprocess(backward_180_left_right_2a, \"backward_180\", \"left_right\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2 = [backward_180_left_right_2a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_left_right_2:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_right_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4SEGMENTEN\n",
    "forward_180_right_backwards2 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_right_backwards2.csv\", sep=';', header=0, skipinitialspace=True)\n",
    "#4 SEGMENTEN\n",
    "forward_180_right_backwards3 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_right_backwards3.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] <= 11719400000000)]\n",
    "f2 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] >= 11719400000000) & (forward_180_right_backwards2[\"time\"] <= 11723600000000)]\n",
    "f3 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] >= 11723600000000) & (forward_180_right_backwards2[\"time\"] <= 11727900000000)]\n",
    "f4 =  forward_180_right_backwards2[(forward_180_right_backwards2[\"time\"] >= 11727900000000) ]\n",
    "\n",
    "f5 =  forward_180_right_backwards3[(forward_180_right_backwards3[\"time\"] >= 11736100000000) & (forward_180_right_backwards3[\"time\"] <= 11740600000000)]\n",
    "f6 =  forward_180_right_backwards3[(forward_180_right_backwards3[\"time\"] >= 11740600000000) & (forward_180_right_backwards3[\"time\"] <= 11744900000000)]\n",
    "f7 =  forward_180_right_backwards3[(forward_180_right_backwards3[\"time\"] >= 11744900000000) & (forward_180_right_backwards3[\"time\"] <= 11749400000000)]\n",
    "f8 =  forward_180_right_backwards3[(forward_180_right_backwards3[\"time\"] >= 11749400000000) & (forward_180_right_backwards3[\"time\"] <= 11754200000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 0.2, 0.7)\n",
    "f2 = preprocess(f2, \"backward_180\", 0.7, 1)\n",
    "f3 = preprocess(f3, \"backward_180\", 0.7, 1)\n",
    "f4 = preprocess(f4, \"backward_180\", 0.8, 1.3)\n",
    "f5 = preprocess(f5, \"backward_180\", 1, 1.1)\n",
    "f6 = preprocess(f6, \"backward_180\", 0.9, 0.8)\n",
    "f7 = preprocess(f7, \"backward_180\", 0.8, 1.1)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_right_backwards_2 = [f1, f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_right_2a = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\backward_180_right_right1.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_right_2a = preprocess(backward_180_right_right_2a, \"backward_180\", \"right_right\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_right_2 = [backward_180_right_right_2a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_right_right_2:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_left_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 SEGMENTEN\n",
    "forward_180_left_otherside1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_left_back_otherside1.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] <= 20761300000000)]\n",
    "f2 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20761300000000) & (forward_180_left_otherside1[\"time\"] <= 20766800000000)]\n",
    "f3 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20766800000000) & (forward_180_left_otherside1[\"time\"] <= 20772100000000)]\n",
    "f4 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20772100000000) & (forward_180_left_otherside1[\"time\"] <= 20777400000000)]\n",
    "f5 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20777400000000) & (forward_180_left_otherside1[\"time\"] <= 20782700000000)]\n",
    "f6 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20782700000000) & (forward_180_left_otherside1[\"time\"] <= 20787800000000)]\n",
    "f7 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20787800000000) & (forward_180_left_otherside1[\"time\"] <= 20793100000000)]\n",
    "f8 =  forward_180_left_otherside1[(forward_180_left_otherside1[\"time\"] >= 20793100000000) & (forward_180_left_otherside1[\"time\"] <= 20798900000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 1.7, 1.1)\n",
    "f2 = preprocess(f2, \"backward_180\", 1.6, 1.7)\n",
    "f3 = preprocess(f3, \"backward_180\", 1.7, 1.1)\n",
    "f4 = preprocess(f4, \"backward_180\", 1.7, 1.1)\n",
    "f5 = preprocess(f5, \"backward_180\", 1.8, 1.2)\n",
    "f6 = preprocess(f6, \"backward_180\", 1.5, 1.3)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.5, 1.3)\n",
    "f8 = preprocess(f8, \"backward_180\", 1.8, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_left_other_side_2 = [f1, f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_left_2a = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\backward_180_left_left.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_left_2a = preprocess(backward_180_left_left_2a, \"backward_180\", \"left_left\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_left_2 = [backward_180_left_left_2a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_left_left_2:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward_180_right_left_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_right_otherside1 = pd.read_csv(r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\forward_180_right_backwards_otherside.csv\", sep=';', header=0, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] <= 21087100000000)]\n",
    "f2 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21087100000000) & (forward_180_right_otherside1[\"time\"] <= 21091500000000)]\n",
    "f3 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21091500000000) & (forward_180_right_otherside1[\"time\"] <= 21095700000000)]\n",
    "f4 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21095700000000) & (forward_180_right_otherside1[\"time\"] <= 21100000000000)]\n",
    "f5 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21100000000000) & (forward_180_right_otherside1[\"time\"] <= 21104500000000)]\n",
    "f6 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21104500000000) & (forward_180_right_otherside1[\"time\"] <= 21109700000000)]\n",
    "f7 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21109700000000) & (forward_180_right_otherside1[\"time\"] <= 21115000000000)]\n",
    "f8 =  forward_180_right_otherside1[(forward_180_right_otherside1[\"time\"] >= 21115000000000) & (forward_180_right_otherside1[\"time\"] <= 21119800000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = preprocess(f1, \"backward_180\", 1.3, 0.5)\n",
    "f2 = preprocess(f2, \"backward_180\", 1, 0.7)\n",
    "f3 = preprocess(f3, \"backward_180\", 0.8, 0.7)\n",
    "f4 = preprocess(f4, \"backward_180\", 0.9, 0.7)\n",
    "f5 = preprocess(f5, \"backward_180\", 1, 0.7)\n",
    "f6 = preprocess(f6, \"backward_180\", 0.9, 1.6)\n",
    "f7 = preprocess(f7, \"backward_180\", 1.7, 0.8)\n",
    "f8 = preprocess(f8, \"backward_180\", 1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_180_right_other_side_2 = [f1, f2, f3, f4, f5, f6, f7, f8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zonder tussenpauzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_left_2a = pd.read_csv(\n",
    "    r\"C:\\Users\\Elise\\Documents\\unif\\master\\semester2\\masterproef\\gitProject\\thesis\\data\\forward_180\\proefpersoon2\\backward_180_right_left1.csv\", \n",
    "    sep=';', header=0, skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_left_2a = preprocess(backward_180_right_left_2a, \"backward_180\", \"right_left\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_right_left_2 = [backward_180_right_left_2a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in backward_180_right_left_2:\n",
    "    f = sampling_freq(df)\n",
    "    freq += f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( not raw):\n",
    "    #segmentation + feature extraction\n",
    "    for i in range(0, len(backward_180_left_right_2)):\n",
    "        backward_180_left_right_2[i] =  feature_extraction_segmentation(backward_180_left_right_2[i],1, True)\n",
    "\n",
    "    for i in range(0, len(backward_180_right_right_2)):\n",
    "        backward_180_right_right_2[i] =  feature_extraction_segmentation(backward_180_right_right_2[i],1, True)\n",
    "\n",
    "    for i in range(0, len(backward_180_left_left_2)):\n",
    "        backward_180_left_left_2[i] =  feature_extraction_segmentation(backward_180_left_left_2[i],1, True)\n",
    "    \n",
    "    for i in range(0, len(backward_180_right_left_2)):\n",
    "        backward_180_right_left_2[i] =  feature_extraction_segmentation(backward_180_right_left_2[i],1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2840, 7)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_left_right_2 = pd.concat(backward_180_left_right_2, ignore_index=True)\n",
    "backward_180_left_right_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 7)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_right_right_2 = pd.concat(backward_180_right_right_2, ignore_index=True)\n",
    "backward_180_right_right_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 7)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_left_left_2 = pd.concat(backward_180_left_left_2, ignore_index=True)\n",
    "backward_180_left_left_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4437, 7)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_180_right_left_2 = pd.concat(backward_180_right_left_2, ignore_index=True)\n",
    "backward_180_right_left_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHUFFLE - BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.min([\n",
    "    backward_180_left_right_2.shape[0], \n",
    "    backward_180_right_right_2.shape[0], \n",
    "    backward_180_left_left_2.shape[0], \n",
    "    backward_180_right_left_2.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2 = shuffle(backward_180_left_right_2).head(shape).copy()\n",
    "backward_180_right_right_2 = shuffle(backward_180_right_right_2).head(shape).copy()\n",
    "backward_180_left_left_2 = shuffle(backward_180_left_left_2).head(shape).copy()\n",
    "backward_180_right_left_2 = shuffle(backward_180_right_left_2).head(shape).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_left_right_2 = backward_180_left_right_2.head(shape).copy()\n",
    "backward_180_right_right_2 = backward_180_right_right_2.head(shape).copy()\n",
    "backward_180_left_left_2 = backward_180_left_left_2.head(shape).copy()\n",
    "backward_180_right_left_2 = backward_180_right_left_2.head(shape).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_180_2 = pd.concat([\n",
    "    backward_180_left_right_2, \n",
    "    backward_180_right_right_2, \n",
    "    backward_180_left_left_2, \n",
    "    backward_180_right_left_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.09065359749383"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean\n",
    "freq = freq/64\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'> Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.min([\n",
    "    backward_180_1.shape[0],\n",
    "    backward_180_2.shape[0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 22)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([\n",
    "    shuffle(backward_180_1).head(shape),\n",
    "    shuffle(backward_180_2).head(shape)\n",
    "])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21648, 7)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([\n",
    "    backward_180_1.head(shape),\n",
    "    backward_180_2.head(shape)\n",
    "])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"backward_180_zonder_pauze_raw.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
